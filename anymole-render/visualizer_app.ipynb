{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from pytorch3d.io import load_obj,load_objs_as_meshes\n",
    "from pytorch3d.renderer import (\n",
    "    PerspectiveCameras,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    HardPhongShader,\n",
    "    PointLights,\n",
    "    look_at_view_transform,\n",
    "    TexturesVertex,\n",
    ")\n",
    "\n",
    "from pytorch3d.structures import join_meshes_as_scene, Meshes\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from pytorch3d.renderer import TexturesVertex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkerboard_texture(verts, device, frequency=8):\n",
    "    \"\"\"\n",
    "    Create a black and white checkerboard texture pattern.\n",
    "    :param verts: Vertices of the mesh\n",
    "    :param device: Device for the tensor (CPU or GPU)\n",
    "    :param frequency: Frequency of the checkerboard pattern\n",
    "    :return: Checkerboard texture tensor\n",
    "    \"\"\"\n",
    "    # Extract X and Z coordinates and normalize them\n",
    "    xz_coords = verts[:, [0, 2]]  # Use the X and Z coordinates for the checkerboard pattern\n",
    "    xz_coords = xz_coords - xz_coords.min(dim=0, keepdim=True)[0]  # Shift to start from 0\n",
    "    xz_coords = xz_coords / xz_coords.max(dim=0, keepdim=True)[0]  # Scale to [0, 1]\n",
    "\n",
    "    # Create the checkerboard pattern\n",
    "    pattern = (torch.floor(xz_coords[:, 0] * frequency) + torch.floor(xz_coords[:, 1] * frequency)) % 2\n",
    "    checkerboard_texture = torch.where(\n",
    "        pattern.unsqueeze(1) == 0,\n",
    "        torch.tensor([1.0, 1.0, 1.0], device=device).unsqueeze(0),  # White color\n",
    "        torch.tensor([0.0, 0.0, 0.0], device=device).unsqueeze(0)   # Black color\n",
    "    ).expand(-1, 3)\n",
    "\n",
    "    return checkerboard_texture\n",
    "\n",
    "def ensure_vertex_texture(mesh):\n",
    "    if not isinstance(mesh.textures, TexturesVertex):\n",
    "        verts = mesh.verts_list()[0]\n",
    "        checkerboard_texture = create_checkerboard_texture(verts, device)\n",
    "        mesh.textures = TexturesVertex(verts_features=[checkerboard_texture])\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshLoader:\n",
    "    def __init__(self, device, obj_folder):\n",
    "        self.device = device\n",
    "        self.obj_folder = obj_folder\n",
    "\n",
    "    def load_mesh(self, filename):\n",
    "        # Load the mesh with material information\n",
    "        obj_path = os.path.join(self.obj_folder, filename)\n",
    "        verts, faces, aux = load_obj(obj_path, device=self.device)\n",
    "\n",
    "        faces_idx = faces.verts_idx\n",
    "\n",
    "        # Create per-vertex colors based on Kd from mtl file\n",
    "        verts_rgb = torch.ones_like(verts)\n",
    "\n",
    "        if aux.material_colors:\n",
    "            for mat_name, mat_props in aux.material_colors.items():\n",
    "                if 'diffuse_color' in mat_props:\n",
    "                    # Use 'diffuse_color' for vertex colors\n",
    "                    diffuse_color = mat_props['diffuse_color']\n",
    "                    verts_rgb = diffuse_color.unsqueeze(0).expand(verts.shape)\n",
    "                    break  # Use the first material with 'diffuse_color'\n",
    "\n",
    "        textures = TexturesVertex(verts_features=[verts_rgb])\n",
    "\n",
    "        mesh = Meshes(verts=[verts], faces=[faces_idx], textures=textures)\n",
    "        return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_position_line(line):\n",
    "    # Line format: Ball 'SphereX' Position: (x, y, z)\n",
    "    match = re.match(r\"Ball '(\\w+)' Position: \\(([-\\d\\.]+), ([-\\d\\.]+), ([-\\d\\.]+)\\)\", line)\n",
    "    if match:\n",
    "        x = float(match.group(2))\n",
    "        y = float(match.group(3))\n",
    "        z = float(match.group(4))\n",
    "        return [x, y, z]\n",
    "    else:\n",
    "        raise ValueError(f\"Line format incorrect: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse motion data (from Motion Example txt)\n",
    "def parse_motion_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    frames = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if i + 1 >= len(lines):\n",
    "            break  # Avoid index error\n",
    "        line1 = lines[i].strip()\n",
    "        line2 = lines[i + 1].strip()\n",
    "        pos1 = parse_position_line(line1)\n",
    "        pos2 = parse_position_line(line2)\n",
    "        frames.append({'Sphere1': pos1, 'Sphere3': pos2})\n",
    "        i += 2\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_mesh(mesh, translation):\n",
    "    # mesh is a Meshes object\n",
    "    # translation is a list or tensor of shape (3,)\n",
    "    verts = mesh.verts_list()[0]\n",
    "    faces = mesh.faces_list()[0]\n",
    "    textures = mesh.textures\n",
    "    verts_translated = verts + torch.tensor(translation, device=device)\n",
    "    new_mesh = Meshes(verts=[verts_translated], faces=[faces], textures=textures)\n",
    "    return new_mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load meshes for ball1, ball2, and ball3 (from Current Base Code)\n",
    "base_folder_path=\"./data/noncharacters\"\n",
    "Motion_data= 'BallPositions_31'\n",
    "mesh_loader = MeshLoader(device, obj_folder=base_folder_path)\n",
    "ball1_mesh_original = mesh_loader.load_mesh(\"ball1.obj\")\n",
    "#ball2_mesh_original = mesh_loader.load_mesh(\"ball2.obj\")  # Static mesh\n",
    "ball3_mesh_original = mesh_loader.load_mesh(\"ball3.obj\")\n",
    "\n",
    "\n",
    "# Read motion data\n",
    "motions = parse_motion_file(f\"{base_folder_path}/{Motion_data}.txt\")\n",
    "num_frames = len(motions)\n",
    "\n",
    "# Set up renderer settings (from Previous Render Code)\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=[320, 512],\n",
    "    blur_radius=0.0,\n",
    "    faces_per_pixel=1,\n",
    ")\n",
    "\n",
    "# Set up lights\n",
    "lights = PointLights(device=device, location=[[2.0, 2.0, -2.0]])\n",
    "\n",
    "# Camera parameters (from Previous Render Code)\n",
    "\n",
    "dist = 1.8\n",
    "elev = 0.0\n",
    "azim = 90.0\n",
    "lookat_x = 0.0\n",
    "lookat_y = 0.6\n",
    "lookat_z = 0.6\n",
    "at = torch.tensor([[lookat_x, lookat_y, lookat_z]], dtype=torch.float32)\n",
    "\n",
    "# Output directory\n",
    "output_dir = f'images/Balls/{Motion_data}_input'\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_grid(width, height, density=100):\n",
    "    \"\"\"\n",
    "    Generate a dense grid of vertices for a mesh that lies flat on the X-Z plane, centered at the origin.\n",
    "    :param width: Width of the grid\n",
    "    :param height: Height of the grid\n",
    "    :param density: Number of divisions along each axis\n",
    "    :return: Dense grid vertices and faces\n",
    "    \"\"\"\n",
    "    x = np.linspace(-width / 2, width / 2, density)\n",
    "    z = np.linspace(-height / 2, height / 2, density)\n",
    "    xz_grid = np.array(np.meshgrid(x, z)).reshape(2, -1).T\n",
    "\n",
    "    # Add a y-component (set to 0 for a flat plane on the X-Z plane)\n",
    "    y = np.zeros((xz_grid.shape[0], 1))\n",
    "    xyz_grid = np.hstack((xz_grid[:, 0:1], y, xz_grid[:, 1:2]))  # [x, y, z] with y = 0\n",
    "\n",
    "    # Create vertices\n",
    "    verts = torch.tensor(xyz_grid, dtype=torch.float32)\n",
    "\n",
    "    # Create faces (triangles) for the grid\n",
    "    faces = []\n",
    "    for i in range(density - 1):\n",
    "        for j in range(density - 1):\n",
    "            # Define two triangles for each square in the grid\n",
    "            v0 = i * density + j\n",
    "            v1 = v0 + 1\n",
    "            v2 = v0 + density\n",
    "            v3 = v2 + 1\n",
    "\n",
    "            faces.append([v0, v2, v1])\n",
    "            faces.append([v2, v3, v1])\n",
    "\n",
    "    faces = torch.tensor(faces, dtype=torch.int64)\n",
    "\n",
    "    return verts, faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/241 [00:00<?, ?it/s]/tmp/ipykernel_20158/3446751243.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos1 = torch.tensor(pos1)\n",
      "/tmp/ipykernel_20158/3446751243.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos3 = torch.tensor(pos3)\n",
      "100%|██████████| 241/241 [00:32<00:00,  7.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for frame_idx, positions in enumerate(tqdm(motions)):\n",
    "    # Get positions\n",
    "    pos1 = positions['Sphere1']\n",
    "    pos3 = positions['Sphere3']\n",
    "    \n",
    "\n",
    "    # Translate meshes according to motion data\n",
    "    ball1_mesh = translate_mesh(ball1_mesh_original, pos1)\n",
    "    #ball2_mesh = ball2_mesh_original  # Static mesh\n",
    "    ball3_mesh = translate_mesh(ball3_mesh_original, pos3)\n",
    "    # Combine meshes into a scene\n",
    "    #plane = load_objs_as_meshes([\"./data/checkerboard/checkerboard.obj\"], device=device)\n",
    "    verts, faces = generate_dense_grid(width=10, height=10, density=200)\n",
    "    # Create the plane mesh with the dense grid\n",
    "    plane_mesh = Meshes(verts=[verts.to(device)], faces=[faces.to(device)])\n",
    "    \n",
    "    #ball1_mesh = ensure_vertex_texture(ball1_mesh_original)\n",
    "    #ball3_mesh = ensure_vertex_texture(ball3_mesh_original)\n",
    "    plane = ensure_vertex_texture(plane_mesh)\n",
    "\n",
    "    scene_mesh = join_meshes_as_scene([ball1_mesh, ball3_mesh,plane_mesh])\n",
    "\n",
    "\n",
    "    # Views and corresponding camera azimuth adjustments\n",
    "    views = {\n",
    "        'front': azim,\n",
    "        'back': azim - 179,\n",
    "        'left': azim - 5,\n",
    "        'right': azim + 5,\n",
    "    }\n",
    "    \n",
    "    if (frame_idx>60) and (frame_idx%30 != 0):\n",
    "        continue\n",
    "    \n",
    "    for view_name, azimuth in views.items():\n",
    "        # Adjust look-at point if necessary (from Previous Render Code)\n",
    "        if view_name == 'left':\n",
    "            at_view = at + torch.tensor([[0, 0, 0]], dtype=torch.float32)\n",
    "        elif view_name == 'right':\n",
    "            at_view = at - torch.tensor([[0, 0, 0]], dtype=torch.float32)\n",
    "        else:\n",
    "            at_view = at\n",
    "        \n",
    "        # Set up camera\n",
    "        R, T = look_at_view_transform(dist=dist, elev=elev, azim=azimuth, at=at_view)\n",
    "        cameras = PerspectiveCameras(device=device, R=R, T=T)\n",
    "\n",
    "        # Set up renderer\n",
    "        renderer = MeshRenderer(\n",
    "            rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
    "            shader=HardPhongShader(device=device, cameras=cameras, lights=lights)\n",
    "        )\n",
    "        renderer.rasterizer.cameras.image_size =[320, 512] \n",
    "        # Render scene\n",
    "        images = renderer(scene_mesh)\n",
    "        image = images[0, ..., :3].cpu().numpy()\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        # Save image\n",
    "        \n",
    "        pos1 = torch.tensor(pos1)\n",
    "        pos3 = torch.tensor(pos3)\n",
    "        position = torch.stack((pos1, pos3)).to('cuda')\n",
    "        screen_pos = renderer.rasterizer.cameras.transform_points_screen(position)\n",
    "\n",
    "        if view_name=='front':\n",
    "            filename = os.path.join(output_dir, f'frame_{frame_idx:04d}.png')\n",
    "            position_name = f\"{output_dir}/frame_{frame_idx:04d}.npy\"\n",
    "            #print(screen_pos)\n",
    "        else:\n",
    "            filename = os.path.join(output_dir, f'{view_name}_{frame_idx:04d}.png')\n",
    "            position_name = f\"{output_dir}/{view_name}_{frame_idx:04d}.npy\"\n",
    "        \n",
    "        image.save(filename)        \n",
    "        np.save(position_name, screen_pos.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output = widgets.interactive_output(draw_image, {\"frame_idx\": frame_idx,\\n                                                 \"azimuth\": azimuth,\\n                                                 \"elevation\": elevation,\\n                                                 \"distance\": distance,\\n                                                 \"lookat_x\": lookat_x,\\n                                                 \"lookat_y\": lookat_y,\\n                                                 \"lookat_z\": lookat_z})\\n\\nsave_img_button = widgets.Button(description=\"Save Image\")\\nsave_img_button.on_click(save_image)\\n\\nsave_vid_button = widgets.Button(description=\"Save Video\")\\nsave_vid_button.on_click(save_video)\\n\\nreset_params_button = widgets.Button(description=\"Reset\")\\nreset_params_button.on_click(reset_value)\\n\\ncontrol_display = widgets.VBox([reset_params_button, cam_display, at_display,\\n                                widgets.HBox([save_img_button, save_vid_button]), #, save_cam_button]),\\n                                frame_idx])\\ndisplay(widgets.HBox([control_display, output]))'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"output = widgets.interactive_output(draw_image, {\"frame_idx\": frame_idx,\n",
    "                                                 \"azimuth\": azimuth,\n",
    "                                                 \"elevation\": elevation,\n",
    "                                                 \"distance\": distance,\n",
    "                                                 \"lookat_x\": lookat_x,\n",
    "                                                 \"lookat_y\": lookat_y,\n",
    "                                                 \"lookat_z\": lookat_z})\n",
    "\n",
    "save_img_button = widgets.Button(description=\"Save Image\")\n",
    "save_img_button.on_click(save_image)\n",
    "\n",
    "save_vid_button = widgets.Button(description=\"Save Video\")\n",
    "save_vid_button.on_click(save_video)\n",
    "\n",
    "reset_params_button = widgets.Button(description=\"Reset\")\n",
    "reset_params_button.on_click(reset_value)\n",
    "\n",
    "control_display = widgets.VBox([reset_params_button, cam_display, at_display,\n",
    "                                widgets.HBox([save_img_button, save_vid_button]), #, save_cam_button]),\n",
    "                                frame_idx])\n",
    "display(widgets.HBox([control_display, output]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
